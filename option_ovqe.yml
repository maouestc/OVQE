dataset:
  train:  # LMDB
    type: OVQEDataset

    root: /data/MFQEv2_dataset
    gt_folder: train_108/raw/
    lq_folder: train_108/HM16.5_LDP/QP37/

    # for dataset lmdb
    gt_path: OVQE_train_gt_15_QP37.lmdb
    lq_path: OVQE_train_lq_15_QP37.lmdb
    meta_info_fp: meta_info.txt

    gt_size: 64  # ground truth patch size: gt_size * gt_size
    use_flip: True
    use_rot: True  # rotation per 90 degrees
    random_reverse: False

    # for datasampler
    enlarge_ratio: 300  # enlarge dataset by randomly cropping.

    # for dataloader
    num_worker_per_gpu: 12  # 12 in total. mainly affect IO speed
    batch_size_per_gpu: 4  # bs=8, divided by 1 GPUs

network:
  radius: 7   # total num of input frame = 2 * radius + 1

train:
  exp_name: OVQE_QP37  # default: timestr. None: ~
  random_seed: 7
  pre-val: False  # evaluate criterion before training, e.g., ori PSNR
  num_iter: !!float 4e+5
  interval_print: !!float 100
  interval_val: !!float 5e+3  # also save model
  pbar_len: 100

  optim:
    type: Adam
    lr: !!float 1e-4  # init lr of scheduler
    betas: [0.9, 0.999]
    eps: !!float 1e-08

  scheduler:
    is_on: False
    type: CosineAnnealingRestartLR
    periods: [!!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4]  # epoch interval
    restart_weights: [1, 0.5, 0.5, 0.5, 0.5, 0.5]
    eta_min: !!float 1e-7

  loss:
    type: CharbonnierLoss
    eps: !!float 1e-6

  criterion:
    type: PSNR
    unit: dB
